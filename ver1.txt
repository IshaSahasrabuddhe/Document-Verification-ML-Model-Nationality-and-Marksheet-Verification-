import cv2
import pytesseract
import numpy as np
import difflib
from skimage.metrics import structural_similarity as ssim
import os

# ------------------- KEYWORDS -------------------
SSC_KEYWORDS = [
    "Maharashtra State Board Of Secondary and Higher Secondary Education, Pune",
    "SECONDARY SCHOOL CERTIFICATE EXAMINATION - STATEMENT OF MARKS",
    "SEAT NO.", "DIST. & SCHOOL NO.", "YEAR OF EXAM", "CENTRE NO.",
    "CANDIDATE'S FULL NAME", "CANDIDATE'S MOTHER'S NAME", "Result"
]
SSC_IDENTIFIERS = ["SECONDARY SCHOOL CERTIFICATE EXAMINATION", "Maharashtra State Board"]

HSC_KEYWORDS = [
    "Maharashtra State Board Of Secondary and Higher Secondary Education",
    "HIGHER SECONDARY CERTIFICATE EXAMINATION",
    "STREAM", "SEAT NO.", "CENTRE NO",
    "MONTH & YEAR OF EXAM", "CANDIDATE'S FULL NAME",
    "CANDIDATE'S MOTHER'S NAME", "Result"
]

CET_KEYWORDS = [
    "Government of Maharashtra",
    "State Common Entrance Test Cell, Maharashtra State, Mumbai",
    "MHT-CET (PCM Group) Score Card",
    "Application Number", "Candidate's Full Name", "Roll No",
    "MHT CET Percentile Score", "Total Percentile Score PCM"
]
CET_IDENTIFIERS = ["MHT-CET (PCM Group) Score Card", "Government of Maharashtra"]

PASSPORT_KEYWORDS = [
    "REPUBLIC OF INDIA", "IND", "INDIAN", "Indian Passport", "Address", "Name of Father",
    "Name of Mother", "MAHARASHTRA", "Type", "Code", "Passport No.", "Surname",
    "Given Name(s)", "Nationality", "Date of Birth", "Place of Birth", "Sex",
    "Date of Issue", "Date of Expiry", "Place of Issue",
    "भारताचे प्रजासत्ताक", "भारतीय", "पत्ता", "वडिलांचे नाव", "मातेचे नाव", "लिंग",
    "जन्म तारीख", "जन्म स्थान", "राष्ट्रीयत्व", "जारी तारीख", "कालबाह्यता तारीख", "जारी ठिकाण"
]

DOMICILE_KEYWORDS = [
    "Tahsil Office", "Certificate of Age, Nationality and Domicile", 
    "Issued by Authorities in the State of Maharashtra",
    "State of 'MAHARASHTRA'", "Nationality", "Domicile", "Certificate",
    "CITIZEN OF INDIA", "PARTICULARS OF PROOFS SUBMITTED", "Signature valid", "Seal"
]

# ------------------- OCR & TEXT EXTRACTION -------------------
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not read image at {image_path}")
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    thresh = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY, 11, 2
    )
    return img, thresh

def extract_text(image_path):
    _, preprocessed = preprocess_image(image_path)
    config = r'--oem 3 --psm 6'
    text = pytesseract.image_to_string(preprocessed, config=config)
    return text

# ------------------- KEYWORD DETECTION -------------------
def check_keywords(text, keywords):
    detected_keywords = [kw for kw in keywords if kw.lower() in text.lower()]
    fuzzy_matches = {
        kw: difflib.get_close_matches(kw, text.split(), n=1, cutoff=0.6)
        for kw in keywords
    }
    return detected_keywords, fuzzy_matches

# ------------------- SYMBOL / SEAL DETECTION -------------------
def detect_symbol(image_path, reference_symbol_path):
    try:
        original = cv2.imread(image_path)
        ref_symbol = cv2.imread(reference_symbol_path)
        if original is None or ref_symbol is None:
            return False, 0

        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        ref_gray = cv2.cvtColor(ref_symbol, cv2.COLOR_BGR2GRAY)

        orb = cv2.ORB_create()
        kp1, des1 = orb.detectAndCompute(original_gray, None)
        kp2, des2 = orb.detectAndCompute(ref_gray, None)

        if des1 is None or des2 is None:
            return False, 0

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)

        return (len(matches) > 20), len(matches)
    except Exception as e:
        print(f"Error detecting symbol: {e}")
        return False, 0

# ------------------- STRUCTURE / LAYOUT VERIFICATION (IMPROVED) -------------------
def check_document_structure(image_path, reference_doc_path):
    """
    Compare document layout using SSIM on edges + ORB keypoint ratio.
    More stable, doesn’t crop, handles same images and rotated/blurred copies better.
    """
    try:
        input_img = cv2.imread(image_path)
        ref_img = cv2.imread(reference_doc_path)
        if input_img is None or ref_img is None:
            print("❌ Could not read one of the images.")
            return 0.0, 0

        # Convert to grayscale
        input_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)
        ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)

        # Resize reference to input shape
        ref_gray = cv2.resize(ref_gray, (input_gray.shape[1], input_gray.shape[0]))

        # Normalize brightness
        input_gray = cv2.equalizeHist(input_gray)
        ref_gray = cv2.equalizeHist(ref_gray)

        # Edge detection
        edges_input = cv2.Canny(input_gray, 80, 200)
        edges_ref = cv2.Canny(ref_gray, 80, 200)

        # Structural similarity
        structure_score, _ = ssim(edges_input, edges_ref, full=True)

        # ORB Keypoint Matching
        orb = cv2.ORB_create(nfeatures=1000)
        kp1, des1 = orb.detectAndCompute(input_gray, None)
        kp2, des2 = orb.detectAndCompute(ref_gray, None)
        if des1 is None or des2 is None or len(kp1) == 0:
            return structure_score * 0.6, 0

        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        matches = bf.match(des1, des2)

        # Keypoint ratio
        layout_match_ratio = len(matches) / max(len(kp1), 1)

        # Combined score (weighted)
        overall_score = (structure_score * 0.6) + (layout_match_ratio * 0.4)

        return overall_score, len(matches)
    except Exception as e:
        print(f"Error checking structure: {e}")
        return 0.0, 0

# ------------------- MAIN VERIFICATION FUNCTION -------------------
def verify_document(image_path, doc_category, doc_type):
    ref_path = os.path.join('reference_documents', doc_category.lower(), f"{doc_type.lower()}_ref.jpg")

    if doc_type.lower() == 'ssc':
        keywords = SSC_KEYWORDS
    elif doc_type.lower() == 'hsc':
        keywords = HSC_KEYWORDS
    elif doc_type.lower() == 'cet':
        keywords = CET_KEYWORDS
    elif doc_type.lower() == 'passport':
        keywords = PASSPORT_KEYWORDS
    elif doc_type.lower() == 'domicile':
        keywords = DOMICILE_KEYWORDS
    else:
        keywords = []

    text = extract_text(image_path)
    detected_keywords, fuzzy_matches = check_keywords(text, keywords)
    keyword_score = len(detected_keywords) / len(keywords) if keywords else 0

    structure_score, structure_matches = check_document_structure(image_path, ref_path)

    seal_detected = False
    seal_matches = 0
    if doc_type.lower() in ['passport', 'domicile']:
        seal_detected, seal_matches = detect_symbol(image_path, ref_path)

    if keyword_score > 0.5 and structure_score > 0.6 and (seal_detected or doc_type.lower() not in ['passport', 'domicile']):
        verification_level = "Verified"
    elif keyword_score > 0.4 or structure_score > 0.4:
        verification_level = "Needs Manual Verification"
    else:
        verification_level = "Rejected"

    return {
        'text': text,
        'detected_keywords': detected_keywords,
        'keyword_score': keyword_score,
        'structure_score': structure_score,
        'structure_matches': structure_matches,
        'seal_detected': seal_detected,
        'seal_matches': seal_matches,
        'verification_level': verification_level,
        'doc_type': doc_type,
        'doc_category': doc_category
    }
